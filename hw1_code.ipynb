{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-61.291725</td>\n",
       "      <td>4.447555</td>\n",
       "      <td>-3.361047</td>\n",
       "      <td>-2.274540</td>\n",
       "      <td>1.852450</td>\n",
       "      <td>1</td>\n",
       "      <td>1.222541</td>\n",
       "      <td>-0.718750</td>\n",
       "      <td>-0.092678</td>\n",
       "      <td>-1.832146</td>\n",
       "      <td>0.541431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.527565</td>\n",
       "      <td>3.725128</td>\n",
       "      <td>-1.259678</td>\n",
       "      <td>1.205772</td>\n",
       "      <td>0.548077</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466484</td>\n",
       "      <td>-2.202273</td>\n",
       "      <td>0.495814</td>\n",
       "      <td>-2.325496</td>\n",
       "      <td>2.913829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-78.563960</td>\n",
       "      <td>5.366005</td>\n",
       "      <td>-0.579791</td>\n",
       "      <td>4.206422</td>\n",
       "      <td>2.016993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930874</td>\n",
       "      <td>-1.194001</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>-0.352840</td>\n",
       "      <td>-1.076339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.450604</td>\n",
       "      <td>1.500686</td>\n",
       "      <td>-1.401609</td>\n",
       "      <td>-1.302531</td>\n",
       "      <td>0.358072</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466832</td>\n",
       "      <td>-0.260097</td>\n",
       "      <td>0.912008</td>\n",
       "      <td>-0.510121</td>\n",
       "      <td>-2.085178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.016755</td>\n",
       "      <td>1.817803</td>\n",
       "      <td>-1.182545</td>\n",
       "      <td>-0.547288</td>\n",
       "      <td>0.668232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159126</td>\n",
       "      <td>0.835107</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>0.370391</td>\n",
       "      <td>-0.149051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-30.633786</td>\n",
       "      <td>3.528683</td>\n",
       "      <td>-0.298072</td>\n",
       "      <td>2.932539</td>\n",
       "      <td>2.896558</td>\n",
       "      <td>1</td>\n",
       "      <td>2.255478</td>\n",
       "      <td>-0.746831</td>\n",
       "      <td>-0.247752</td>\n",
       "      <td>-0.632649</td>\n",
       "      <td>-0.959097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-32.880433</td>\n",
       "      <td>3.343772</td>\n",
       "      <td>-2.263303</td>\n",
       "      <td>-1.182834</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352842</td>\n",
       "      <td>0.762762</td>\n",
       "      <td>-1.033225</td>\n",
       "      <td>0.476829</td>\n",
       "      <td>0.954998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-16.332526</td>\n",
       "      <td>2.465531</td>\n",
       "      <td>-2.017796</td>\n",
       "      <td>-1.570061</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.294179</td>\n",
       "      <td>-2.211614</td>\n",
       "      <td>-0.276436</td>\n",
       "      <td>0.065659</td>\n",
       "      <td>0.254701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-14.898616</td>\n",
       "      <td>2.245702</td>\n",
       "      <td>-2.903066</td>\n",
       "      <td>-3.560431</td>\n",
       "      <td>0.815529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>-0.862668</td>\n",
       "      <td>0.280049</td>\n",
       "      <td>-1.327336</td>\n",
       "      <td>0.799153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-55.481439</td>\n",
       "      <td>4.389830</td>\n",
       "      <td>-2.227154</td>\n",
       "      <td>-0.064477</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.664088</td>\n",
       "      <td>-1.496463</td>\n",
       "      <td>0.839991</td>\n",
       "      <td>-0.265596</td>\n",
       "      <td>1.145578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y        x1        x2        x3        x4  x5        X1  \\\n",
       "0   -61.291725  4.447555 -3.361047 -2.274540  1.852450   1  1.222541   \n",
       "1   -37.527565  3.725128 -1.259678  1.205772  0.548077   1  1.466484   \n",
       "2   -78.563960  5.366005 -0.579791  4.206422  2.016993   1  0.930874   \n",
       "3    -5.450604  1.500686 -1.401609 -1.302531  0.358072   1  0.466832   \n",
       "4    -7.016755  1.817803 -1.182545 -0.547288  0.668232   1  0.159126   \n",
       "..         ...       ...       ...       ...       ...  ..       ...   \n",
       "995 -30.633786  3.528683 -0.298072  2.932539  2.896558   1  2.255478   \n",
       "996 -32.880433  3.343772 -2.263303 -1.182834  0.069328   1  0.352842   \n",
       "997 -16.332526  2.465531 -2.017796 -1.570061  0.000317   0  0.294179   \n",
       "998 -14.898616  2.245702 -2.903066 -3.560431  0.815529   0  0.242152   \n",
       "999 -55.481439  4.389830 -2.227154 -0.064477  0.051599   1 -1.664088   \n",
       "\n",
       "           X2        X3        X4        X5  \n",
       "0   -0.718750 -0.092678 -1.832146  0.541431  \n",
       "1   -2.202273  0.495814 -2.325496  2.913829  \n",
       "2   -1.194001  0.843049 -0.352840 -1.076339  \n",
       "3   -0.260097  0.912008 -0.510121 -2.085178  \n",
       "4    0.835107  0.977348  0.370391 -0.149051  \n",
       "..        ...       ...       ...       ...  \n",
       "995 -0.746831 -0.247752 -0.632649 -0.959097  \n",
       "996  0.762762 -1.033225  0.476829  0.954998  \n",
       "997 -2.211614 -0.276436  0.065659  0.254701  \n",
       "998 -0.862668  0.280049 -1.327336  0.799153  \n",
       "999 -1.496463  0.839991 -0.265596  1.145578  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datasets imported from R code\n",
    "train = pd.read_csv(\"data/ml_data.csv\")\n",
    "test = pd.read_csv(\"data/ml_testdata.csv\")\n",
    "\n",
    "train50 = pd.read_csv(\"data/train50.csv\")#training data with d=50\n",
    "test50 = pd.read_csv(\"data/test50.csv\")#testing data with d=50\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree truncating by depth\n",
    "    #y_average: predicted y vector that will be returned when the algorithm terminates\n",
    "    #depth: variable that indicates the current depth the recursive algorithm it is on\n",
    "    #maxdepth: maximum depth the tree reaches before returning the predicted y-value\n",
    "\n",
    "def decisiontreedepth(data, y_average, depth, maxdepth):\n",
    "    \n",
    "    #stopping conditions, assigns predicted y-values\n",
    "    if((depth >= maxdepth) | (len(data) <= 1)):\n",
    "        for d in data.index:\n",
    "            y_average[d] = np.mean(data['y'])      \n",
    "            \n",
    "        return y_average\n",
    "    \n",
    "    \n",
    "    maxcor = 0 #maximum correlation to y\n",
    "    xi = ''# x variable with maximum correlation to y\n",
    "    \n",
    "    \n",
    "    #get highest correlated xi value for decision tree\n",
    "    for i in data:        \n",
    "        r = np.corrcoef(data['y'], data[i])\n",
    "            \n",
    "        if((abs(r[0,1]) > maxcor) & (i != 'y')):\n",
    "            maxcor = abs(r[0,1])          \n",
    "            xi = i\n",
    "    \n",
    "    #sort data by xi\n",
    "    sortedx = data.sort_values(by=xi)\n",
    "    \n",
    "    minerror = 0\n",
    "    minindex = 0\n",
    "    \n",
    "    #find split of data that gives the smallest total error\n",
    "    for k in range(len(data)-2):        \n",
    "        leftdata = sortedx.iloc[:(k+1), :]\n",
    "        rightdata = sortedx.iloc[(k+1):, :]\n",
    "            \n",
    "        lefterror = sum((leftdata['y'] - (np.mean(leftdata['y'])))**2)/len(leftdata)\n",
    "        righterror = sum((rightdata['y'] - (np.mean(rightdata['y'])))**2)/len(rightdata)\n",
    "        \n",
    "        totalerror = ((len(leftdata)/len(data))*lefterror) + ((len(rightdata)/len(data))*righterror)\n",
    "        \n",
    "        if(k == 0 or totalerror < minerror):\n",
    "            minerror = totalerror\n",
    "            minindex = k + 1\n",
    "                    \n",
    "        \n",
    "    \n",
    "    if(len(data) == 2):\n",
    "        minindex = 1\n",
    "    \n",
    "    #splits the dataset into two subsets for recursion\n",
    "    ldata = sortedx.iloc[:minindex, :]\n",
    "    rdata = sortedx.iloc[minindex:, :]\n",
    "    \n",
    "    #recursively constructs decision tree until maximum depth is reached\n",
    "    y_average = decisiontreedepth(ldata, y_average, depth+1, maxdepth)\n",
    "    y_average = decisiontreedepth(rdata, y_average, depth+1, maxdepth)\n",
    "    \n",
    "    return y_average\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -19.314724\n",
      "1     -22.941665\n",
      "2     -57.364206\n",
      "3     -29.375196\n",
      "4     -29.375196\n",
      "         ...    \n",
      "995   -22.941665\n",
      "996   -44.239831\n",
      "997    -6.900236\n",
      "998   -15.303169\n",
      "999   -22.941665\n",
      "Name: y, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#individual tree testing\n",
    "ymean = test['y'].copy()\n",
    "decision_tree = decisiontreedepth(test, ymean, 0, 5)\n",
    "print(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\castl\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\castl\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112.75843054064276, 38.17382246154596, 14.927364230670149, 7.696119925886805, 4.111621033036673, 2.196420476538805, 1.1041325614453166, 0.48130915699160387]\n"
     ]
    }
   ],
   "source": [
    "#calculates the errors of decision trees over a range of depth values. These errors will be used for plotting.\n",
    "y_actual = test['y'].copy()\n",
    "\n",
    "errors = []\n",
    "for e in range(1, 9):\n",
    "    y_pred = test['y'].copy()\n",
    "    errors.append(sum((decisiontreedepth(test, y_pred, 0, e)-y_actual)**2)/len(test))\n",
    "print(errors)\n",
    "#print(sum((decision_tree-y_actual)**2)/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree truncating by sample size\n",
    "    #y_average: predicted y vector that will be returned when the algorithm terminates\n",
    "    #minsize: minimum sample size the branches can have before returning the predicted y-value\n",
    "\n",
    "def decisiontreesize(data, y_average, minsize):\n",
    "    \n",
    "    #stopping conditions, assigns predicted y-values\n",
    "    if(len(data) <= minsize):       \n",
    "        for d in data.index:\n",
    "            y_average[d] = np.mean(data['y'])\n",
    "            \n",
    "        return y_average\n",
    "    \n",
    "    \n",
    "    maxcor = 0 #maximum correlation to y\n",
    "    xi = '' #x variable with maximum correlation to y\n",
    "    \n",
    "    \n",
    "    #get highest correlated xi value for decision tree\n",
    "    for i in data:        \n",
    "        r = np.corrcoef(data['y'], data[i])\n",
    "            \n",
    "        if((abs(r[0,1]) > maxcor) & (i != 'y')):\n",
    "            maxcor = abs(r[0,1])          \n",
    "            xi = i\n",
    "    \n",
    "    #sorts data by xi\n",
    "    sortedx = data.sort_values(by=xi)\n",
    "    \n",
    "    minerror = 0\n",
    "    minindex = 0\n",
    "    \n",
    "    #find split of data that gives the smallest total error\n",
    "    for k in range(len(data)-2):\n",
    "        leftdata = sortedx.iloc[:(k+1), :]\n",
    "        rightdata = sortedx.iloc[(k+1):, :]\n",
    "            \n",
    "        lefterror = sum((leftdata['y'] - (np.mean(leftdata['y'])))**2)/len(leftdata)\n",
    "        righterror = sum((rightdata['y'] - (np.mean(rightdata['y'])))**2)/len(rightdata)\n",
    "        \n",
    "        totalerror = ((len(leftdata)/len(data))*lefterror) + ((len(rightdata)/len(data))*righterror)\n",
    "        \n",
    "        if(k == 0 or totalerror < minerror):\n",
    "            minerror = totalerror\n",
    "            minindex = k + 1\n",
    "                    \n",
    "    \n",
    "    \n",
    "    if(len(data) == 2):\n",
    "        minindex = 1\n",
    "    \n",
    "    #splits the dataset into two subsets for recursion\n",
    "    ldata = sortedx.iloc[:minindex, :]\n",
    "    rdata = sortedx.iloc[minindex:, :]\n",
    "    \n",
    "    \n",
    "    #recursively constructs decision tree until minimum sample size is reached or passed\n",
    "    y_average = decisiontreesize(ldata, y_average, minsize)\n",
    "    y_average = decisiontreesize(rdata, y_average, minsize)\n",
    "    \n",
    "    return y_average\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     -19.314724\n",
      "1     -22.078372\n",
      "2     -58.495591\n",
      "3     -27.388726\n",
      "4     -31.692989\n",
      "         ...    \n",
      "995   -24.306224\n",
      "996   -46.823721\n",
      "997    -7.086996\n",
      "998   -15.303169\n",
      "999   -22.078372\n",
      "Name: y, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#individual tree testing\n",
    "ymean2 = test['y'].copy()\n",
    "decision_tree2 = decisiontreesize(test, ymean2, 50)\n",
    "print(decision_tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.18155296037939, 77.24071091974238, 28.111645245591912, 18.636768880280474, 5.950090990631368, 3.7131819564608968, 1.0036260343775647, 0.5292267625359737]\n"
     ]
    }
   ],
   "source": [
    "#calculates the errors of decision trees over a range of sample sizes. These errors will be used for plotting.\n",
    "y_actual2 = test['y'].copy()\n",
    "\n",
    "sizes = [999, 500, 250, 100, 50, 25, 10, 5]\n",
    "errors2 = []\n",
    "for s in sizes:\n",
    "    y_pred2 = test['y'].copy()\n",
    "    errors2.append(sum((decisiontreesize(test, y_pred2, s)-y_actual2)**2)/len(test))\n",
    "print(errors2)\n",
    "#print(sum((decision_tree2-y_actual2)**2)/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
